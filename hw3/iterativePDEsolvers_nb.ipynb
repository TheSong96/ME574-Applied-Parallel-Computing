{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Solvers for Elliptic PDEs\n",
    "\n",
    "In \"Intro to Finite Difference Methods for PDEs\" we classified the $2^{nd}$ order quasilinear PDEs as elliptic, parabolic, or hyperbolic, and we started looking as solvers for elliptic equations.\n",
    "\n",
    "In particular, we looked at the 2D Laplace equation:\n",
    "- 2D Cartesian (rectangular, coord-aligned) domain (coords: $\\{x,y\\}$)\n",
    "- Dirichlet BCs (values specified on boundary)\n",
    "\n",
    "$$ \\nabla^2 u = \\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2} = 0 \\text{ on } x \\in [0,L_x]; \\; y \\in [0,L_y]$$\n",
    "\n",
    "BCs: $u(0,y)=u(L_x,y)=u(0,x)=0, \\; u(L_y,x) = U$\n",
    "\n",
    "After discretizing the spatial domain to a regular 2D grid, we discretized the PDE by substituting with central difference approximations for the derivatives:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial^2u}{\\partial x^2} & \\rightarrow \\frac{1}{h^2}(u_{i-1,j}-2u_{i,j}+u_{i+1,j}) + O(h^2) \\\\\n",
    "\\frac{\\partial^2u}{\\partial y^2} & \\rightarrow \\frac{1}{h^2} (u_{i,j-1} -2 u_{i,j} + u_{i,j+1}) + O(h^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "- For each internal grid point get equation of the form:\n",
    "\n",
    "$$ \\nabla^2 u = \\frac{\\partial ^2 u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2} \\rightarrow u_{i-1,j}+u_{i+1,j}+u_{i,j-1} + u_{i,j+1} -4u_{i,j} = 0$$\n",
    "\n",
    "or in code format:\n",
    "\n",
    "`u[i-1,j] + u[i+1,j] + u[i,j-1] + u[i,j+1] - 4*u[i,j] == 0`\n",
    "\n",
    "$\\implies$ __5-point stencil computation__: \n",
    "\n",
    "![stencil_5point](stencil_5point.png)\n",
    "\n",
    "With no source terms (so right-hand side is zero), we can solve for $u_{i,j}$ in terms of values at neighboring gridpoints. At equilibrium (for the actual solution for the steady-state temperature distribution), the following relation should satisfied (in the limit as the grid is refined):\n",
    "\n",
    "$$u_{i,j} = \\frac{1}{4} (u_{i-1,j} + u_{i+1,j} +u_{i,j-1} +u_{i,j+1} )$$\n",
    "\n",
    "We turn this into an iterative scheme by adding an iteration count superscript, so that at each iteration the value at each grid point is replaced by the stencil based on the neighbors (in this case, by the average of teh neighboring values).\n",
    "\n",
    "$$u^{k+1}_{i,j} = \\frac{1}{4} (u^k_{i-1,j} + u^k_{i+1,j} +u^k_{i,j-1} +u^k_{i,j+1} )$$\n",
    "\n",
    "Game plan for computing solution:\n",
    "  - Repeatedly update each grid point. \n",
    "  - Converge to numerical solution!?\n",
    "  - This approach is known as Jacobi iteration.\n",
    "\n",
    "Let's take a look at implementation and convergence issues:\n",
    "\n",
    "While truncation error is $O(h^2)$, refining grid may not reduce error.\n",
    "\n",
    "Also need to worry about rate of convergence:\n",
    "- Jacobi spectral radius (magnitude of largest eigenvalue of the BIG matrix): \n",
    "$$\\rho_{jacobi} \\approx 1-\\frac{1}{2} (\\pi^2 h^2)$$\n",
    "- Good news: $\\rho_{jacobi} < 1 \\implies$ convergence\n",
    "- Bad news: grid refinement $\\implies h \\to 0, \\rho_{jacobi} \\to 1$\n",
    "- Attempts to reduce truncation error by refinement cause SLOW convergence\n",
    "- Number of iterations for given accuracy $\\sim O(h^2)$\n",
    "- Total operation count $\\sim O(N^4) \\implies$ Serial = Painful\n",
    "- Sub-optimal memory usage: <br>new values computed from old values $\\iff$ need a copy of the array  \n",
    "\n",
    "Alternatives:\n",
    "- Gauss-Seidel: systematically use updated (improved) values\n",
    "- Can operate \"in place\" with single version of array\n",
    "- Spectral radius: \n",
    "$$\\rho_{GS} \\approx 1-(\\pi^2 h^2)$$ \n",
    "    - Improved\n",
    "    - But only by factor of 2\n",
    "    - CUDA parallel version will be non-deterministic\n",
    "- Red-Black version (inspired by checkerboard)\n",
    "  - Grid points of one color updated bsed only on other color\n",
    "  - Run kernel twice:\n",
    "    - update red points\n",
    "    - update black points\n",
    "  - Deterministic and has improved Gauss-Seidel convergence rate\n",
    "- Successive over-relaxation\n",
    "  - Think of the change in values of $u$ as a direction to move to reduce the residual error\n",
    "\n",
    "$$\\Delta u_{i,j} = u^{k+1}_{i,j}-u^k_{i,j} = \\frac{1}{4} (u^k_{i-1,j} + u^k_{i+1,j} +u^k_{i,j-1} +u^k_{i,j+1} -4u^k_{i,j})$$\n",
    "\n",
    "```\n",
    "du = (u[i-1,j]+u[i+1,j]+u[i,j-1]+u[i,j+1]-4.*u[i,j])/4.\n",
    "```\n",
    "\n",
    "  - If it is good to move in that direction, wouldn't it be better to mover farther in that direction?\n",
    "\n",
    "$$u^{k+1}_{i,j} = u^k_{i,j} + w * \\Delta u_{i,j}$$\n",
    "```\n",
    "u[i,j] = u[i,j] + w * du\n",
    "```\n",
    "  - `w` is the over-relaxation factor\n",
    "\n",
    "  - Don't get carried away: $w>2$ $\\implies$ divergence\n",
    "  - Optimal value: $w_{opt} = 2-2 \\pi h$\n",
    "  - Optimal convergence: \n",
    "  $$\\rho_{opt} = 1 - 2 \\pi h $$\n",
    "  - As grid is refined, convergence multiplier approaches 1 more slowly; iterations required for given accuracy closer to $O(N)$\n",
    "\n",
    "Our interest lies in parallelizing these methods and characterizing their performance\n",
    "\n",
    "- Compared to CPU world:\n",
    "  - less concerned about operation counts\n",
    "  - more concerned about memory and iterations (when forced to serialize)\n",
    "  - 2D tiled approach using shared memory with halo values\n",
    "\n",
    "Let's look at sample serial and parallel codes..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}