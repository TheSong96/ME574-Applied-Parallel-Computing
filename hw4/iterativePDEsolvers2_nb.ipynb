{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Solvers for Elliptic PDEs\n",
    "\n",
    "In \"Intro to Finite Difference Methods for PDEs\" we classified the $2^{nd}$ order quasilinear PDEs as elliptic, parabolic, or hyperbolic, and we started looking as solvers for elliptic equations.\n",
    "\n",
    "In particular, we looked at the 2D Laplace equation:\n",
    "- 2D Cartesian (rectangular, coord-aligned) domain (coords: $\\{x,y\\}$)\n",
    "- Dirichlet BCs (values specified on boundary)\n",
    "\n",
    "$$ \\nabla^2 u = \\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2} = 0 \\text{ on } x \\in [0,L_x]; \\; y \\in [0,L_y]$$\n",
    "\n",
    "BCs: $u(0,y)=u(L_x,y)=u(0,x)=0, \\; u(L_y,x) = sin(\\pi x)$\n",
    "\n",
    "After discretizing the spatial domain to a regular 2D grid, we discretized the PDE by substituting with central difference approximations for the derivatives:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial^2u}{\\partial x^2} & \\rightarrow \\frac{1}{h^2}(u_{i-1,j}-2u_{i,j}+u_{i+1,j}) + O(h^2) \\\\\n",
    "\\frac{\\partial^2u}{\\partial y^2} & \\rightarrow \\frac{1}{h^2} (u_{i,j-1} -2 u_{i,j} + u_{i,j+1}) + O(h^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "- For each internal grid point get equation of the form:\n",
    "\n",
    "$$ \\nabla^2 u = \\frac{\\partial ^2 u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2} \\rightarrow u_{i-1,j}+u_{i+1,j}+u_{i,j-1} + u_{i,j+1} -4u_{i,j} = 0$$\n",
    "\n",
    "or in code format:\n",
    "\n",
    "`u[i-1,j] + u[i+1,j] + u[i,j-1] + u[i,j+1] - 4*u[i,j] == 0`\n",
    "\n",
    "$\\implies$ __5-point stencil computation__: \n",
    "\n",
    "![stencil_5point](stencil_5point.png)\n",
    "\n",
    "With no source terms (so right-hand side is zero), we can solve for $u_{i,j}$ in terms of values at neighboring gridpoints. At equilibrium (for the actual solution for the steady-state temperature distribution), the following relation should satisfied (in the limit as the grid is refined):\n",
    "\n",
    "$$u_{i,j} = \\frac{1}{4} (u_{i-1,j} + u_{i+1,j} +u_{i,j-1} +u_{i,j+1} )$$\n",
    "\n",
    "We turn this into an iterative scheme by adding an iteration count superscript, so that at each iteration the value at each grid point is replaced by the stencil based on the neighbors (in this case, by the average of teh neighboring values).\n",
    "\n",
    "$$u^{k+1}_{i,j} = \\frac{1}{4} (u^k_{i-1,j} + u^k_{i+1,j} +u^k_{i,j-1} +u^k_{i,j+1} )$$\n",
    "\n",
    "Game plan for computing solution:\n",
    "  - Repeatedly update each grid point. \n",
    "  - Converge to numerical solution!?\n",
    "  - This approach is known as Jacobi iteration.\n",
    "\n",
    "Let's take a look at implementation and convergence issues:\n",
    "\n",
    "While truncation error is $O(h^2)$, refining grid may not reduce error.\n",
    "\n",
    "Also need to worry about rate of convergence:\n",
    "- Jacobi spectral radius (magnitude of largest eigenvalue of the BIG matrix): \n",
    "$$\\rho_{jacobi} \\approx 1-\\frac{1}{2} (\\pi^2 h^2)$$\n",
    "- Good news: $\\rho_{jacobi} < 1 \\implies$ convergence\n",
    "- Bad news: grid refinement $\\implies h \\to 0, \\rho_{jacobi} \\to 1$\n",
    "- Attempts to reduce truncation error by refinement cause SLOW convergence\n",
    "- Number of iterations for given accuracy $\\sim O(h^2)$\n",
    "- Total operation count $\\sim O(N^4) \\implies$ Serial = Painful\n",
    "- Sub-optimal memory usage: <br>new values computed from old values $\\iff$ need a copy of the array  \n",
    "\n",
    "Alternatives:\n",
    "- Gauss-Seidel: systematically use updated (improved) values\n",
    "- Can operate \"in place\" with single version of array\n",
    "- Spectral radius: \n",
    "$$\\rho_{GS} \\approx 1-(\\pi^2 h^2)$$ \n",
    "    - Improved\n",
    "    - But only by factor of 2\n",
    "    - CUDA parallel version will be non-deterministic\n",
    "- Red-Black version (inspired by checkerboard)\n",
    "  - Grid points of one color updated bsed only on other color\n",
    "  - Run kernel twice:\n",
    "    - update red points\n",
    "    - update black points\n",
    "  - Deterministic and has improved Gauss-Seidel convergence rate\n",
    "- Successive over-relaxation\n",
    "  - Think of the change in values of $u$ as a direction to move to reduce the residual error\n",
    "\n",
    "$$\\Delta u_{i,j} = u^{k+1}_{i,j}-u^k_{i,j} = \\frac{1}{4} (u^k_{i-1,j} + u^k_{i+1,j} +u^k_{i,j-1} +u^k_{i,j+1} -4u^k_{i,j})$$\n",
    "\n",
    "```\n",
    "du = (u[i-1,j]+u[i+1,j]+u[i,j-1]+u[i,j+1]-4.*u[i,j])/4.\n",
    "```\n",
    "\n",
    "  - If it is good to move in that direction, wouldn't it be better to mover farther in that direction?\n",
    "\n",
    "$$u^{k+1}_{i,j} = u^k_{i,j} + w * \\Delta u_{i,j}$$\n",
    "```\n",
    "u[i,j] = u[i,j] + w * du\n",
    "```\n",
    "  - `w` is the over-relaxation factor\n",
    "\n",
    "  - Don't get carried away: $w>2$ $\\implies$ divergence\n",
    "  - Optimal value: $w_{opt} = 2-2 \\pi h$\n",
    "  - Optimal convergence: \n",
    "  $$\\rho_{opt} = 1 - 2 \\pi h $$\n",
    "  - As grid is refined, convergence multiplier approaches 1 more slowly; iterations required for given accuracy closer to $O(N)$\n",
    "\n",
    "### Improved stencils\n",
    "\n",
    "Another way to strive for improved performance of the solver is to use stencils with higher order truncation error. The relatively obvious approach to this is to employ a tensor product stencil with a larger radius. For example, one could use the second derivative finite difference operator with radius 2:\n",
    "\n",
    "$$ \\frac{\\partial^2 u_{i,j}}{\\partial x^2} = \\frac{1}{12 h^2} (-u_{i-2,j}+16 u_{i-1,j}-30u_{i,j}+16 u_{i+1,j}-u_{i+2,j}) + O(h^4)$$\n",
    "\n",
    "and the corresponding expression for $\\frac{\\partial^2 u_{i,j}}{\\partial y^2}$ to produce a 9-point stencil of radius 2 with $4^{th}$-order truncation error. This would lead to the possibility of improved accuracy, but at the cost of slightly more than doubling the required number of halo values.\n",
    "\n",
    "However, there is another version of a 9-point Laplacian stencil to consider. This stencil has radius 1 but includes the central point along with all 8 of its neighbors including along the diagonals of the grid. The corresponding approximation formula is:\n",
    "\n",
    "$$∇^2\n",
    "_9u_{i,j} = \\frac{1}{6 h^2}\n",
    "[u_{i−1,j−1} + 4u_{i−1,j} + 4 u_{i+1,j} + u_{i+1,j+1}\n",
    "−20u_{i,j} + u_{i+1,j−1} + 4u_{i,j−1} + 4u_{i,j+1} + u_{i−1,j+1}] $$\n",
    "\n",
    "so the stencil coefficients are $-1$ at the center, $1/4$ at the edge, and $1/20$ at the corner (multipled by a constanct factor $\\frac{20}{6h^2}$).\n",
    "\n",
    "The relation to the exact Laplace operator is:\n",
    "\n",
    "$$∇^2_9 u_(x_i, y_i) = ∇^2u + \\frac{h^2}{2}[u_{xxxx} + 2u_{xxyy} + u_{yyyy}] + O(h^4)$$\n",
    "\n",
    "which appears to also have second-order truncation error. However, the leading order error term turns out to involve the Laplacian of the Laplacian (also know as the ___biharmonic operator___ which you may have run into previously when studying elasticity), and we can rewrite the expression as:\n",
    "\n",
    "$$∇^2_9 u(x_i, y_i) = ∇^2u + \\frac{h^2}{2} \\nabla^2(\\nabla^2 u) + O(h^4)$$\n",
    "\n",
    "and take advantage of this relationship to improve solution accuracy. Substituting the 9-point Laplacian stencil into the Poisson equation, $\\nabla^2u = F$, gives:\n",
    "\n",
    "$$∇^2_9 u(x_i, y_i) = F + \\frac{h^2}{2} \\nabla^2F + O(h^4)$$\n",
    "\n",
    "If the forcing term $F$ is sufficiently smooth (twice-differentiable), we can intentially introduce the \"error\" $\\frac{h^2}{2} \\nabla^2F$ into the forcing term, and solve with the 9-point stencil to obtain a solution with $4^{th}$-order truncation error. Laplace's equation corresponds to the case when $F=0$, so $\\nabla^2F=0$ and the leading error term automatically vanishes and the 9-point stencil produces a $4^{th}$-order accurate solution without needing to introduce a fictitious error term.\n",
    "\n",
    "Our interest lies in parallelizing these methods and characterizing their performance\n",
    "\n",
    "- Compared to CPU world:\n",
    "  - less concerned about operation counts\n",
    "  - more concerned about memory and iterations (when forced to serialize)\n",
    "  - 2D tiled approach using shared memory with halo values\n",
    "\n",
    "Let's look at sample serial and parallel codes...\n",
    "\n",
    "The listing below implements iterative solutions (including Jacobi iteration, Gauss-Seidel iteration, and Successive Over-relaxation) for the sample Laplace equation problem presented earlier in the notebook. Be selecting a method, number of grid points, and number of iterations, several salient results can be demonstrated:\n",
    "\n",
    "- Each of the iterations does converge toward the exact solution.\n",
    "- The rate of convergence decreases as the grid is refined by increasing the number of grid points.\n",
    "- Refining the grid does not suffice to decrease the error; the number of iterations must also be increased.\n",
    "- To achieve similar errors, it takes about 2 Jacobi updates for each Gauss-Seidel update.\n",
    "- Successive over-relaxation provides a significant improvement in the convergence rate.\n",
    "  \n",
    "```\n",
    "File: jacobi_serial.py\n",
    "01: # #%%\n",
    "02: import numpy as np\n",
    "03: import matplotlib.pyplot as plt\n",
    "04: from math import sin, sinh\n",
    "05: \n",
    "06: NX, NY = 11,11\n",
    "07: iters = 1 #NX*NX\n",
    "08: PI = np.pi\n",
    "09: method = 'Jacobi' #choices: 'Jacobi','Gauss-Seidel', 'SOR' \n",
    "10: \n",
    "11: def mean_update(u, method):\n",
    "12:     '''\n",
    "13:     update 2D array with non-boundary elements replaced by average of 4 nearest neighbors (on Cartesian grid)\n",
    "14:     Args:\n",
    "15:         u: 2D numpy array of floats\n",
    "16:         method: string specifying 'Jacobi', 'Gauss-Seidel' or 'SOR'\n",
    "17:     Returns:\n",
    "18:         updated numpy array with same shape as u\n",
    "19:     '''\n",
    "20:     nx, ny = np.shape(u)\n",
    "21: \n",
    "22:     if method == 'Jacobi':\n",
    "23:         u_new = np.copy(u)\n",
    "24:         for i in range(1,nx-1):\n",
    "25:             for j in range(1,ny-1):\n",
    "26:                 u_new[i,j] = (u[i-1,j]+u[i+1,j]+u[i,j-1]+u[i,j+1])/4.\n",
    "27:         return u_new\n",
    "28: \n",
    "29:     if method == 'Gauss-Seidel':\n",
    "30:         for i in range(1,nx-1):\n",
    "31:             for j in range(1,ny-1):\n",
    "32:                 u[i,j] = (u[i-1,j]+u[i+1,j]+u[i,j-1]+u[i,j+1])/4.\n",
    "33:         return u\n",
    "34: \n",
    "35:     if method == 'SOR':\n",
    "36:         h = 1./(nx-1)\n",
    "37:         w = 2. * (1-2*PI*h)\n",
    "38:         for i in range(1,nx-1):\n",
    "39:             for j in range(1,ny-1):\n",
    "40:                 u[i,j] =  u[i,j] + w*(u[i-1,j]+u[i+1,j]+u[i,j-1]+u[i,j+1]-4.*u[i,j])/4.\n",
    "41:         return u\n",
    "42: \n",
    "43: def main():\n",
    "44:     #Compute exact solution\n",
    "45:     exact = np.zeros(shape=[NX,NY], dtype=np.float32)\n",
    "46:     for i in range(NX):\n",
    "47:         for j in range(NY):\n",
    "48:             exact[i,j]= sin(i*PI/(NX-1)) * sinh(j*PI/(NY-1))/sinh(PI)\n",
    "49:     \n",
    "50:     #serial iteration results\n",
    "51:     u = np.zeros(shape=[NX,NY], dtype=np.float32)\n",
    "52:     for i in range(NX):\n",
    "53:         u[i,NX-1]= sin(i*PI/(NX-1))\n",
    "54:     for k in range(iters):\n",
    "55:         u = mean_update(u, method)\n",
    "56:     \n",
    "57:     error = np.max(np.abs(u-exact))\n",
    "58:     print(\"%s, NX = %d, iters = %d => max error: %5.2e\"  %(method, NX, iters, error))\n",
    "59: \n",
    "60:     xvals = np.linspace(0., 1.0, NX)\n",
    "61:     yvals = np.linspace(0., 1.0, NY)\n",
    "62:     X,Y = np.meshgrid(xvals, yvals)\n",
    "63:     levels = [0.025, 0.1, 0.25, 0.50, 0.75]\n",
    "64:     plt.contourf(X,Y,exact.T, levels = levels)\n",
    "65:     plt.contour(X,Y,u.T, levels = levels,\n",
    "66:         colors = 'r', linewidths = 4)\n",
    "67:     plt.axis([0,1,0,1])\n",
    "68:     plt.show()\n",
    "69: \n",
    "70: if __name__ == '__main__':\n",
    "71:     main()\n",
    "72:\n",
    "```\n",
    "\n",
    "Now let's move on to look at a parallel implementation of Jacobi iteration. Salient features to note include:\n",
    "\n",
    "- The code implements a \"tiled\" approach reading a block of data (plus halo values) into a shared memory array where it can be accessed efficiently.\n",
    "- The parallel code only implements Jacobi iteration but, in addition to the 5-point stencil, it also includes the 9-point stencil of radius 1 that provides $4^{th}$-order accuracy.\n",
    "- Two device arrays, `d_u` and `d_v`, are created and they take turns serving as input and output arrays.\n",
    "- The results are not copied back to the host at every step, so `copy_to_host()` is called only once at the very end of the wrapper function `update()`.\n",
    "\n",
    "\n",
    "## Lines 18-55 of the listing below provide a template you can use in your implementation of other 2D tiled methods.\n",
    "```\n",
    "File: jacobi_parallel.py\n",
    "001: # #%%\n",
    "002: import numpy as np\n",
    "003: import matplotlib.pyplot as plt\n",
    "004: from math import sin, sinh\n",
    "005: from numba import jit, cuda, float32, int32\n",
    "006: \n",
    "007: NX, NY = 21, 21\n",
    "008: iters = NX*NX//2\n",
    "009: PI = np.pi\n",
    "010: STENCIL_POINTS = 9 #specify 5 or 9 for points in stencil\n",
    "011: TPB = 8\n",
    "012: RAD = 1\n",
    "013: SH_N = 10\n",
    "014: \n",
    "015: #kernel with 2D shared memory array including halo\n",
    "016: @cuda.jit\n",
    "017: def updateKernel(d_v, d_u, edge, corner):\n",
    "018:     i,j = cuda.grid(2)\n",
    "019:     dims = d_u.shape\n",
    "020:     if i >= dims[0] or j >= dims[1]:\n",
    "021:         return\n",
    "022:     NX, NY = cuda.blockDim.x, cuda.blockDim.y\n",
    "023:     t_i, t_j = cuda.threadIdx.x, cuda.threadIdx.y\n",
    "024:     sh_i, sh_j = t_i + RAD, t_j + RAD\n",
    "025: \n",
    "026:     sh_u = cuda.shared.array(shape = (SH_N,SH_N), dtype = float32)\n",
    "027: \n",
    "028:     #Load regular values\n",
    "029:     sh_u[sh_i, sh_j] = d_u[i, j]\n",
    "030:     \n",
    "031:     #Halo edge values\n",
    "032:     if t_i<RAD:\n",
    "033:         sh_u[sh_i - RAD, sh_j] = d_u[i-RAD, j]\n",
    "034:         sh_u[sh_i + NX , sh_j] = d_u[i+NX , j]\n",
    "035: \n",
    "036:     if t_j<RAD:\n",
    "037:         sh_u[sh_i, sh_j - RAD] = d_u[i, j - RAD]\n",
    "038:         sh_u[sh_i, sh_j + NY ] = d_u[i, j + NY ]\n",
    "039: \n",
    "040:     #Halo corner values\n",
    "041:     if t_i<RAD and t_j<RAD:\n",
    "042:         #upper left\n",
    "043:         sh_u[sh_i - RAD, sh_j - RAD] = d_u[i-RAD, j - RAD]\n",
    "044:         sh_u[sh_i - RAD, sh_j - RAD] = d_u[i-RAD, j - RAD]\n",
    "045:         #upper right\n",
    "046:         sh_u[sh_i + NX, sh_j - RAD] = d_u[i + NX, j - RAD]\n",
    "047:         sh_u[sh_i + NX, sh_j - RAD] = d_u[i + NX, j - RAD]\n",
    "048:         #lower left\n",
    "049:         sh_u[sh_i - RAD, sh_j + NY] = d_u[i-RAD, j + NY]\n",
    "050:         sh_u[sh_i - RAD, sh_j + NY] = d_u[i-RAD, j + NY]\n",
    "051:         #lower right\n",
    "052:         sh_u[sh_i + NX, sh_j + NX] = d_u[i + NX, j + NY]\n",
    "053:         sh_u[sh_i + NX, sh_j + NY] = d_u[i + NX, j + NY]\n",
    "054: \n",
    "055:     cuda.syncthreads()\n",
    "056: \n",
    "057:     if i>0 and j>0 and i<dims[0]-1 and j<dims[1]-1:\n",
    "058:         d_v[i, j] = \\\n",
    "059:             sh_u[sh_i-1, sh_j -1]*corner + \\\n",
    "060:             sh_u[sh_i, sh_j -1]*edge + \\\n",
    "061:             sh_u[sh_i+1, sh_j -1]*corner + \\\n",
    "062:             sh_u[sh_i-1, sh_j]*edge + \\\n",
    "063:             sh_u[sh_i, sh_j]*0. + \\\n",
    "064:             sh_u[sh_i+1, sh_j]*edge + \\\n",
    "065:             sh_u[sh_i-1, sh_j +1]*corner + \\\n",
    "066:             sh_u[sh_i, sh_j + 1] * edge + \\\n",
    "067:             sh_u[sh_i+1, sh_j +1]*corner\n",
    "068:             # edge * (sh_u[sh_i-1, sh_j] + sh_u[sh_i+1, sh_j] + \\\n",
    "069:             #     sh_u[sh_i, sh_j-1] + sh_u[sh_i, sh_j+1]) + \\\n",
    "070:             # corner * (sh_u[sh_i-1, sh_j -1] + sh_u[sh_i+1, sh_j +1] + \\\n",
    "071:             #     sh_u[sh_i-1, sh_j +1] + sh_u[sh_i+1, sh_j-1])\n",
    "072: \n",
    "073: def update(u, iter_count, edge, corner):\n",
    "074:     d_u = cuda.to_device(u)\n",
    "075:     d_v = cuda.to_device(u)\n",
    "076:     dims = u.shape\n",
    "077:     gridSize = [(dims[0]+TPB-1)//TPB, (dims[1]+TPB-1)//TPB]\n",
    "078:     blockSize = [TPB, TPB]\n",
    "079: \n",
    "080:     for k in range(iter_count):\n",
    "081:         updateKernel[gridSize, blockSize](d_v, d_u, edge, corner)\n",
    "082:         updateKernel[gridSize, blockSize](d_u, d_v, edge, corner)\n",
    "083: \n",
    "084:     return d_u.copy_to_host()\n",
    "085: \n",
    "086: \n",
    "087: def main():\n",
    "088:     #Compute exact solution\n",
    "089:     exact = np.zeros(shape=[NX,NY], dtype=np.float32)\n",
    "090:     for i in range(NX):\n",
    "091:         for j in range(NY):\n",
    "092:             exact[i,j]= sin(i*PI/(NX-1)) * sinh(j*PI/(NY-1))/sinh(PI)\n",
    "093: \n",
    "094:     #parallel iteration results\n",
    "095:     u = np.zeros(shape=[NX,NY], dtype=np.float32)\n",
    "096:     for i in range(NX):\n",
    "097:         u[i,NX-1]= sin(i*PI/(NX-1)) #boundary conditions\n",
    "098:     if STENCIL_POINTS == 5:\n",
    "099:         edge, corner = 0.25, 0\n",
    "100:     elif STENCIL_POINTS == 9:\n",
    "101:         edge, corner = 0.20, 0.05\n",
    "102:     else:\n",
    "103:         print(\"Supported values of STENCIL_POINTS: {5,9}\")\n",
    "104:         return\n",
    "105:     u = update(u, iters, edge, corner)\n",
    "106: \n",
    "107:     error = np.max(np.abs(u-exact))\n",
    "108:     print(\"NX = %d, iters = %d => max error: %5.2e\"  %(NX, iters, error))\n",
    "109: \n",
    "110:     xvals = np.linspace(0., 1.0, NX)\n",
    "111:     yvals = np.linspace(0., 1.0, NY)\n",
    "112:     X,Y = np.meshgrid(xvals, yvals)\n",
    "113:     levels = [0.025, 0.1, 0.25, 0.50, 0.75]\n",
    "114:     plt.contourf(X,Y,exact.T, levels = levels)\n",
    "115:     plt.contour(X,Y,u.T, levels = levels,\n",
    "116:         colors = 'r', linewidths = 4)\n",
    "117:     plt.axis([0,1,0,1])\n",
    "118:     plt.show()\n",
    "119: \n",
    "120: if __name__ == '__main__':\n",
    "121:     main()\n",
    "122: \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
